---
layout: diy
title: Publications
---

<head>
<style>
a { text-decoration : none; }
a:hover { text-decoration : underline; }
a, a:visited { color : #6e6f71; }
p { font-size : 16px; }
h3 { font-size : 18px; margin : 8; padding : 0; }
.container { width : 1000px;}
.publogo { width: 100 px; margin-right : 20px; float : left; border : 10px;}
.publication { clear : left; padding-bottom : 0px; }
.publication p { height : 180px; padding-top : 0px;}
.publication strong { font-size : 17px; color : #990036; }
.publication strong a { font-size : 17px; color : #990036; }
</style>
</head>

<div class="container">

<!-- <a href="https://scholar.google.com/citations?user=tGTa-EAAAAAJ&hl=en" target="_blank">Google Scholar</a>
<br> -->
<font color="grey" size="3">
  * Equal contribution. ♡ Project lead. ✉ corresponding / co-corresponding author.
</font>

<br>

<div class="publication">
  <img src="../static/pubs/ZCH23.png" class="publogo" width="200 px" height="180 px">
     <p> 
      <strong>
      Hierarchical Auto-Organizing System for Open-Ended Multi-Agent Navigation
      </strong>
      <br>
      <b>Zhonghan Zhao*</b>, Kewei Chen*, Dongxu Guo*, Wenhao Chai, Tian Ye, Yanting Zhang✉, Gaoang Wang✉
      <br>
      <em>arXiv Preprint.</em>
      <br>
      <a href="https://arxiv.org/abs/2403.08282">[Paper]</a>
      <br>
      <font color="grey" size="2">
      HAS is a hierarchical auto-organizing multi-agent navigation system for MLM embodied agents.
      </font>
    </p>
    <p> 
      <strong>
      See and think: Embodied agent in virtual environment
      </strong>
      <br>
      <b>Zhonghan Zhao*</b>, Wenhao Chai*, Xuan Wang*, Li Boyi, Shengyu Hao, Shidong Cao, Tian Ye, Jenq-Neng Hwang✉, Gaoang Wang✉
      <br>
      <em>arXiv Preprint.</em>
      <br>
      <a href="https://arxiv.org/abs/2311.15209">[Paper]</a>
      <br>
      <font color="grey" size="2">
      STEVE is a comprehensive and visionary embodied agent in the Minecraft virtual environment. STEVE comprises three key components: vision perception, language instruction, and code action. 
      </font>
    </p>
     <p> 
      <strong>
      Devil in the Number: Towards Robust Multi-modality Data Filter
      </strong>
      <br>
      Yichen Xu, Zihan Xu, Wenhao Chai, <b>Zhonghan Zhao</b>, Enxin Song, Gaoang Wang✉
      <br>
      <em>arXiv Preprint.</em>
      <br>
      <a href="https://arxiv.org/abs/2309.13770">[Paper]</a>
      <br>
      <font color="grey" size="2">
      Devil in the number involves reevaluating the CLIP scores after eliminating these influences to filter multi-modality data sets on a web scale. 
      </font>
    </p>
    <p> 
      <strong>
      UniAP: Towards Universal Animal Perception in Vision via Few-shot Learning
      </strong>
      <br>
      Meiqi Sun*, <b>Zhonghan Zhao*</b>, Wenhao Chai, Hanjun Luo, Shidong Cao, Yanting Zhang, Jenq-Neng Hwang, Gaoang Wang✉
      <br>
      <em>arXiv Preprint.</em>
      <br>
      <a href="https://arxiv.org/abs/2308.09953">[Paper]</a>
      <br>
      <font color="grey" size="2">
      UniAP is a novel Universal Animal Perception model that leverages few-shot learning to enable cross-species perception among various visual tasks.
      </font>
    </p>
    <p> 
    <strong>
    A Survey of Deep Learning in Sports Applications: Perception, Comprehension, and Decision
    </strong>
    <br>
    <b>Zhonghan Zhao*</b>, Wenhao Chai*, Shengyu Hao, Wenhao Hu, Guanhong Wang, Shidong Cao, Gaoang Wang✉, Mingli Song, Jenq-Neng Hwang
    <br>
    <em>arXiv Preprint.</em>
    <br>
    <a href="https://arxiv.org/abs/2307.03353">[Paper]</a>
    <br>
    <font color="grey" size="2">
    Our survey provides valuable reference material for researchers interested in deep learning applications within the sporting industry while shedding light on its potential to utilize sports data for analysis.
    </font>
  </p>
</div>
